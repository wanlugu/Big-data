# Online learning
1. Your data doesnâ€™t fit into memory
2. You expect the distribution of your data to morph or drift over time
3. Your data is a function of time (e.g. stock prices)
offline learning: batch
online learning: stochatic
# noSQL
document, graph, queries

########## hadoop, spark ###########
frameworks for data distributing and retrieving
hadoop focuses on diksed based and a map-reduced schema, both accommodate multiple types of data and by parallel workers
HDFS (storage layer) then yarn (resource manage layer)

# The Hadoop Distributed File System: A Storage System for Big Data
HDFS split file across nodes for parallel access: 
two key components - 
1. NameNode for metadata (one per cluster), 
2. DataNode for block storage (one per machine) listens to NameNode for block creation, deletion, replication (fault tolerance, data locality)
# Yarn, resouce manager for hadoop 
Interact with applications and schedule resources to them
Enable multiple applications on beyond HDFS
# mapreduce, multi-machine or multi-core in single machine
split into n subsets, assign to n machineas, then combine together, nx speed up
summation over training set
Limitation: only for batch, only for indenpendent tasks, not interactive analysis, issue with small file, slow processing, latency, no catching, no real-time data streaming, no delta iteration
process: map node (parallelization on input) - shuffle and sort (parallelization data sorting)- reduce (parallelization over data group)
# spark
Limitation: no file management system, no real-time processing, expensive (large store size), small file (store in zip, need uncompressed)
